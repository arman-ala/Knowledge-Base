# 3.2.1. Docker Architecture

2025-08-09 10:49
Status: #DONE
Tags: [[Docker]]

---

# Docker Architecture: A Friendly Guide to Containers

Imagine you’re packing a suitcase for a trip—everything you need fits neatly inside, ready to go anywhere. That’s what Docker does for applications! It’s a platform that wraps up apps and their dependencies into lightweight, portable containers. Docker’s architecture is like a team of helpers working together to make this happen. Let’s unpack it step by step.

## The Big Picture: How Docker Works

Docker runs on a **client-server model**, meaning you’ve got a chatty client giving orders and a busy server making it all happen. But it’s more than just two pieces—there’s a whole crew involved: a client, a daemon, registries, and some cool objects like images and containers. Together, they create, manage, and run those handy containers. Ready to meet the team?

## Meet the Docker Crew

Here’s who’s behind the scenes in Docker’s architecture:

### Docker Client: Your Voice to Docker
The **Docker Client** is your go-to tool for talking to Docker. Picture it as your walkie-talkie—when you type commands like `docker run` or `docker build` in your terminal, the client sends those instructions to the Docker Daemon. You can use the `docker` CLI, Docker Desktop, or even REST APIs to get the job done. It’s flexible too—it can talk to a daemon on your machine or one far away.

### Docker Daemon: The Hardworking Manager
The **Docker Daemon** (or `dockerd`) is the engine room. Running quietly in the background, it listens for your commands via the Docker API and gets to work. It’s the one building images, starting containers, managing networks, and keeping storage in check. Think of it as the manager who handles all the Docker objects—images, containers, networks, and volumes—making sure everything runs smoothly.

####  Docker Daemon major functionalities
*Image Management* 
> The Docker daemon handles image management, which involves creating, storing, and retrieving Docker images. Images are lightweight, portable templates used to create containers, containing the application code, dependencies, and runtime environment. The daemon interacts with registries (like Docker Hub) to pull images or push locally built ones, ensuring that containers can be instantiated from these images efficiently.

*Image Builds* 
> Image builds refer to the Docker daemon's ability to construct Docker images from a set of instructions defined in a Dockerfile. The daemon interprets commands like FROM, RUN, COPY, and CMD to layer the image step-by-step, caching intermediate layers for efficiency. This process allows developers to automate and standardize the creation of container images tailored to their applications.

*REST API*  
> The Docker daemon exposes a REST API that allows users and external tools to interact with it programmatically. Through this API, you can manage containers, images, networks, and volumes by sending HTTP requests. For example, commands like docker run or docker pull issued via the Docker CLI are translated into API calls that the daemon processes, making it a central hub for Docker operations.

*Authentication*  
> Authentication in the context of the Docker daemon involves securing access to its operations and resources. The daemon can be configured to require authentication for API requests, ensuring that only authorized users or systems can manage containers or pull/push images. This often integrates with mechanisms like TLS certificates or user credentials to protect against unauthorized access.

*Security*  
> The Docker daemon enforces security features to protect both the host system and containers. It isolates containers using Linux kernel features like namespaces and cgroups, ensuring that processes in one container cannot interfere with others or the host. Additionally, the daemon supports user namespaces for privilege separation, seccomp profiles to limit system calls, and AppArmor/SELinux policies to enhance container security.

*Core Networking*
> Core networking refers to the Docker daemon's management of container networking. It sets up default networks (like the bridge network) for containers to communicate with each other or the outside world. The daemon handles IP address allocation, port mapping, and DNS resolution, and supports custom network configurations (e.g., overlay networks for multi-host communication) to meet specific application needs.

*Orchestration*
> Orchestration, as mentioned, involves the Docker daemon's role in managing container lifecycles at a basic level, such as starting, stopping, and restarting containers. While advanced orchestration is typically handled by tools like Docker Swarm or Kubernetes, the daemon provides the foundational capabilities—like scheduling containers on the host and ensuring they run as intended—that orchestration systems build upon.

*Volume Management*
> An important functionality not listed is volume management. The Docker daemon manages data persistence for containers through volumes, which are directories that exist outside the container's filesystem and can be mounted into containers. This allows data to persist even if a container is deleted, and the daemon facilitates sharing volumes between containers or between a container and the host.

*Resource Management*
> Another unlisted functionality is resource management. The Docker daemon uses cgroups to control and limit the resources (CPU, memory, disk I/O) that containers can use. This ensures that no single container can monopolize the host's resources, maintaining system stability and allowing fine-tuned allocation based on application needs.

*Logging and Monitoring*
> The Docker daemon also handles logging and monitoring of containers. It collects logs from containerized applications (e.g., stdout and stderr streams) and makes them accessible via commands like docker logs. Additionally, the daemon provides basic monitoring through APIs or commands like docker stats, which show real-time resource usage (CPU, memory, etc.) for running containers.

### Docker Registry: The Image Library
The **Docker Registry** is like a bookshelf for Docker images. It’s where these app blueprints are stored and shared. The default spot is Docker Hub, a public hub full of ready-made images, but you can set up your own private registry too. When you run `docker pull`, the daemon grabs an image from the registry; with `docker push`, you send one up to share.

### Docker Objects: The Stuff Docker Manages
Docker works with a few key items, called **objects**:
1. **Images**: These are the read-only templates—think of them as recipe cards with your app’s code, runtime, libraries, and dependencies.
2. **Containers**: The live version of an image. They’re isolated little worlds running your app, sharing the host’s kernel but keeping their own files and networks.
3. **Networks**: These let containers talk to each other or the outside world.
4. **Volumes**: Persistent storage that sticks around, even if a container stops, perfect for sharing data.

## How They Talk: Client-Server Chitchat

Here’s how the client and daemon team up:

1. **You Give a Command**: Type something like `docker run nginx`, and the client packages up your request.
2. **Message Sent**: The client sends it to the daemon over a REST API—usually through a local Unix socket (`/var/run/docker.sock`) or a TCP connection for remote setups.
3. **Daemon Takes Action**: The daemon gets the memo, does the work (like pulling an image or starting a container), and sends back a status update to the client for you to see.

If an image isn’t local, the daemon will fetch it from the registry before getting started.

## Step-by-Step: Docker in Action

Let’s see how this plays out with some everyday tasks.

### Building an Image
1. You write a `Dockerfile`—a simple list of steps to build your image.
2. Run `docker build` from the client.
3. The client hands it off to the daemon.
4. The daemon follows the `Dockerfile`, stacking layers (like adding ingredients), and saves the finished image locally.

### Running a Container
1. Type `docker run <image-name>` in the client.
2. The client tells the daemon to go for it.
3. The daemon checks for the image locally—if it’s missing, it grabs it from the registry.
4. It spins up a container, setting up isolation with namespaces and cgroups, and starts your app.

### Managing Containers
Commands like `docker ps` (to list containers), `docker stop`, or `docker rm` go from the client to the daemon, which checks or tweaks the containers as needed.

## Keeping Containers Cozy and Separate

Docker uses some clever tricks from the Linux kernel to keep containers isolated and efficient:

### Namespaces: Private Spaces for Everyone
- **PID**: Gives each container its own set of process IDs.
- **NET**: Keeps network interfaces separate.
- **MNT**: Isolates file systems.
- **UTS**: Lets containers have their own hostnames.
- **IPC**: Separates communication between processes.

### Control Groups (cgroups): Playing Fair with Resources
Cgroups make sure no container hogs the CPU, memory, or disk I/O. It’s like a referee ensuring everyone gets their fair share.

### Union File System: Layers of Efficiency
Docker stacks images in read-only layers using systems like OverlayFS or AUFS. When a container runs, it adds a writable layer on top—smart and space-saving!

## Local or Remote: How They Connect

- **Local**: By default, the client and daemon chat over a Unix socket (`/var/run/docker.sock`) on the same machine.
- **Remote**: Set the daemon to listen on a TCP socket, add some TLS security, and you can control it from anywhere.

## The Docker Engine: The Core Team

The **Docker Engine** ties it all together:
1. **Docker Daemon**: Runs the show and manages objects.
2. **REST API**: The communication highway.
3. **Docker CLI**: Your command-line buddy.

## A Quick Example: From Scratch to Running

Let’s tie it all together with a real scenario:
1. You write a `Dockerfile` and run `docker build -t myapp .`.
2. The client sends the build job to the daemon.
3. The daemon grabs any base images it needs, builds `myapp` layer by layer, and stores it.
4. You run `docker run myapp`.
5. The client tells the daemon, which creates a container, sets up isolation, and starts your app.
6. Boom—your app’s running in its own little world!

## Wrapping It Up

Docker’s architecture is a **client-server** dream team. The **Docker Client** sends your wishes to the **Docker Daemon** via a REST API. The daemon handles the heavy lifting—managing images, containers, networks, and volumes—using Linux kernel features for isolation and resource control. Meanwhile, the **Docker Registry** keeps your images ready to share. It’s a flexible, scalable setup that’s made Docker a go-to for developers everywhere.

**Final Answer**: Docker’s architecture is **client-server** brilliance—the client talks to the daemon over a REST API, and the daemon runs the show, leveraging Linux tricks to keep everything isolated and efficient.
