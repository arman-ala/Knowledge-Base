# 5.5. Docker Network Examples

2025-08-09 10:49
Status: #DONE
Tags: [[Docker]]

---
# 5.5. Docker Network Examples
## Inspect Network Example
```bash
docker network inspect bridge
```

```bash
[
    {
        "Name": "bridge",
        "Id": "0d6197930daeb0a54c13f89036e24fa9f6c7a078522f784038c0b2ce336a5043",
        "Created": "2025-04-15T17:41:52.402061322+03:30",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv4": true,
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.17.0.0/16",
                    "Gateway": "172.17.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "28f1ffcd8b1d1efafe66dba4b5f72fe039464db8003eaf57ae89fb72b22e4950": {
                "Name": "centos8_3",
                "EndpointID": "7bea29dcad99cd1dc48a76965bb6ec336630268f79cfc8f99cbd51d877b04642",
                "MacAddress": "6e:77:8c:e7:e6:be",
                "IPv4Address": "172.17.0.4/16",
                "IPv6Address": ""
            },
            "a0248ded5dc8ffbd893db832d957416db51ec2191d97db388067ab1e32b1bbaa": {
                "Name": "centos_1",
                "EndpointID": "6cc3dc5924f29ec53127a526f5885d2934bcb90a02919408a4d9112a9bac7cfd",
                "MacAddress": "36:a5:ef:ab:41:1c",
                "IPv4Address": "172.17.0.2/16",
                "IPv6Address": ""
            },
            "d8da5e6b71cc21378f1552418d9b0fbe635ab82a81aa361d978eb1b747c3e73e": {
                "Name": "centos_t",
                "EndpointID": "c9d7e4980c512f56e64d27a8281b6218aa4c05b7173a454d52287b6d7a9c525d",
                "MacAddress": "fe:6c:aa:33:32:95",
                "IPv4Address": "172.17.0.3/16",
                "IPv6Address": ""
            }
        },
        "Options": {
            "com.docker.network.bridge.default_bridge": "true",
            "com.docker.network.bridge.enable_icc": "true",
            "com.docker.network.bridge.enable_ip_masquerade": "true",
            "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0",
            "com.docker.network.bridge.name": "docker0",
            "com.docker.network.driver.mtu": "1500"
        },
        "Labels": {}
    }
]
```

## User-defined Network

### Step 1: Creating a User-Defined Network
We start with the command:
```bash
docker network create localnet
```

Here, we’re creating a **user-defined bridge network** named `localnet`. In Docker, a bridge network is a private internal network on the host that allows containers to communicate with each other while remaining isolated from the host’s network (unless explicitly exposed, e.g., via port mapping). By default, Docker uses a bridge network called `bridge` for containers if no network is specified, but creating a user-defined network like `localnet` gives us more control and isolation.

When we create `localnet`, Docker sets up a new bridge interface on the host system. This bridge acts as a virtual switch that containers attached to `localnet` will connect to. Docker also assigns a subnet to this network (e.g., something like `172.18.0.0/16`, as we’ll see in the output). Each container attached to this network will get an IP address from this subnet.

---

### Step 2: Running a Container on the `localnet` Network
Next, we run:
```bash
docker run -itd --name alpine_1 --network localnet alpine:latest
```

Here’s what this command does:
- `docker run`: Starts a new container.
- `-itd`: Runs the container in interactive mode (`-i`), with a terminal (`-t`), and in detached mode (`-d`) so it runs in the background.
- `--name alpine_1`: Names the container `alpine_1`.
- `--network localnet`: Attaches the container to our user-defined network `localnet`.
- `alpine:latest`: Uses the latest version of the `alpine` image, a lightweight Linux distribution.

So, we’ve launched a container named `alpine_1` that’s connected to the `localnet` network. Since it’s on `localnet`, Docker will assign it an IP address from the subnet associated with `localnet`. The container will also have its own network namespace, meaning it has its own isolated network stack, including a virtual Ethernet interface that connects to the bridge on the host.

---

### Step 3: Examining Network Interfaces on the Host with `ip a`
Now, we run `ip a` on the host system to inspect the network interfaces. The output you provided shows several interfaces, but let’s focus on the relevant one tied to `localnet`:

```bash 
ip a
docker network ls
```

![[5.4_network.png]]

```
35: br-f66db64f6a0b: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default
    link/ether f6:85:8f:ea:f6:b4 brd ff:ff:ff:ff:ff:ff
    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-f66db64f6a0b
    valid_lft forever preferred_lft forever
    inet6 fe80::f485:8fff:feea:f6b4/64 scope link proto kernel_ll
    valid_lft forever preferred_lft forever
```

This is the bridge interface created by Docker for the `localnet` network. Let’s break down the details:
- `br-f66db64f6a0b`: The name of the bridge interface. The `br-` prefix indicates it’s a bridge, and `f66db64f6a0b` is a unique identifier generated by Docker for this network.
- `<BROADCAST,MULTICAST,UP,LOWER_UP>`: The interface is up and running, capable of broadcasting and multicasting.
- `mtu 1500`: The Maximum Transmission Unit (MTU) is 1500 bytes, standard for Ethernet.
- `qdisc noqueue`: The queuing discipline is set to `noqueue`, meaning packets are processed directly without queuing (common for virtual interfaces).
- `state UP`: The interface is active.
- `link/ether f6:85:8f:ea:f6:b4`: The MAC address of the bridge.
- `brd ff:ff:ff:ff:ff:ff`: The broadcast address for the MAC layer.
- `inet 172.18.0.1/16`: The IP address assigned to the bridge interface is `172.18.0.1`, with a subnet mask of `/16` (i.e., the subnet is `172.18.0.0/16`, which spans `172.18.0.0` to `172.18.255.255`).
- `brd 172.18.255.255`: The broadcast address for the IP subnet.
- `scope global`: The IP address has global scope on the host (within the Docker network context).
- `valid_lft forever preferred_lft forever`: The IP address lease is valid indefinitely.

This bridge interface (`br-f66db64f6a0b`) acts as the gateway for the `localnet` network. Containers attached to `localnet` will use `172.18.0.1` as their default gateway for outbound traffic.

We also see a virtual Ethernet (veth) interface tied to the container `alpine_1`:

```
36: veth2561c5c@1f2: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br-f66db64f6a0b state UP group default
    link/ether b2:f0:0f:30:48:3a brd ff:ff:ff:ff:ff:ff link-netsnid 3
    inet6 fe80::b0f0:fff:fe30:483a/64 scope link proto kernel_ll
    valid_lft forever preferred_lft forever
```

- `veth2561c5c@1f2`: This is a virtual Ethernet (veth) interface pair. One end (`veth2561c5c`) is on the host, and the other end (`if2`) is inside the container `alpine_1`.
- `master br-f66db64f6a0b`: This veth interface is attached to the bridge `br-f66db64f6a0b` (the `localnet` bridge).
- `link-netsnid 3`: Indicates the network namespace ID (netns) for the container, which is part of Docker’s internal bookkeeping.
- The rest of the details (MTU, state, etc.) are similar to the bridge interface.

The veth pair acts as a pipe: one end connects to the bridge on the host, and the other end is inside the container’s network namespace, allowing the container to communicate with the bridge (and thus other containers on the same network or the outside world via NAT, if configured).

---

### Step 4: Running `ip a` Inside the Container `alpine_1`
![[5.4_ip_result-2.png]]
Now, if we run `ip a` inside the `alpine_1` container (as you mentioned), we’d see the container’s network interfaces. Based on the setup, the output would look something like this:

```
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
    valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
    valid_lft forever preferred_lft forever

2: eth0@if36: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default
    link/ether aa:bb:cc:dd:ee:ff brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0
    valid_lft forever preferred_lft forever
    inet6 fe80::aabb:ccff:fedd:eeff/64 scope link
    valid_lft forever preferred_lft forever
```

Here’s what we see inside the container:
- `lo`: The loopback interface, standard for any Linux system (including containers), with the IP `127.0.0.1`.
- `eth0@if36`: This is the container’s end of the veth pair. The `@if36` indicates it’s paired with the host’s veth interface (which we saw as `veth2561c5c@1f2`, where `if36` corresponds to the interface index `36` on the host).
- `inet 172.18.0.2/16`: The container has been assigned the IP address `172.18.0.2` on the `localnet` subnet (`172.18.0.0/16`). Notice how this IP comes right after the bridge’s IP (`172.18.0.1`), which is what you pointed out: the container’s IP starts after the network’s first IP (the bridge’s IP).
- `brd 172.18.255.255`: The broadcast address matches the subnet of `localnet`.
- `scope global`: The IP is globally reachable within the `localnet` network.

---
![[5.4_ip_result.png]]
### Connecting the Dots: How IPs Are Assigned
When we created the `localnet` network, Docker assigned it the subnet `172.18.0.0/16`. The bridge interface (`br-f66db64f6a0b`) takes the first usable IP in the subnet, which is `172.18.0.1`. This IP acts as the gateway for all containers on the `localnet` network.

When we launched `alpine_1`, Docker’s DHCP-like mechanism assigned it the next available IP in the subnet, which is `172.18.0.2`. If we were to launch another container on the same network (e.g., `alpine_2`), it would likely get `172.18.0.3`, and so on. This is why you observed that the container’s IP “starts after the network’s first IP”—it’s a sequential assignment starting from the bridge’s IP.

---

### Additional Context from the Output
The output also shows other interfaces on the host, like `docker0` (the default bridge network) and other veth interfaces for other containers (e.g., `vethbF565b05@if2`, `veth41f0b46@if2`). These are unrelated to `localnet` but indicate other containers are running on the host, likely on different networks (e.g., the default `bridge` network or another user-defined network like `docknet`).

For example:
- `docker0` has the IP `172.17.0.1/16`, which is the default bridge network’s subnet.
- Other veth interfaces (e.g., `vethbF565b05@if2`) are tied to containers on `docker0` or other bridges.

The `arman-ala@DOCKER` table you included lists network interfaces and their properties, confirming that `br-f66db64f6a0b` is a bridge associated with `localnet`.

---

### Summary
Here’s the flow of what we did:
1. We created a user-defined bridge network called `localnet` using `docker network create localnet`. This created a bridge interface (`br-f66db64f6a0b`) on the host with the IP `172.18.0.1/16`.
2. We launched a container (`alpine_1`) attached to `localnet` using `docker run --network localnet`. Docker assigned the container the IP `172.18.0.2`, the next available address after the bridge’s IP.
3. On the host, `ip a` showed the bridge (`br-f66db64f6a0b`) and a veth interface (`veth2561c5c`) connecting the container to the bridge.
4. Inside the container, `ip a` showed the container’s interface (`eth0`) with the IP `172.18.0.2`, confirming the sequential IP assignment.

This setup allows `alpine_1` to communicate with other containers on `localnet` (if any) via the bridge, using `172.18.0.1` as its gateway. It’s a clean, isolated networking setup, which is one of the key benefits of using user-defined bridge networks in Docker.

---

assume that we have 4 containers: alpine_1, alpine_2, alpine_3, alpine_4. the first two are connected to localnet network which is a user-defined bridge.
the last two containers are using the docker default bridge network.
```bash
docker run -itd --name alpine_1 --network localnet alpine:latest
```

```bash
docker run -itd --name alpine_2 --network localnet alpine:latest
```

```bash
docker exec alpine_1 ip a
```

![[5.4_result_ip-alpine1.png]]

```bash
docker exec alpine_2 ip a
```

![[5.4_result_ip-alpine2.png]]

```bash
docker network inspect localnet
```

![[5.4_result_inspect_localnet.png]]

```bash
docker exec alpine_1 ping 172.18.0.3
```

![[5.4_result_exec_alpine1.png]]

```bash
docker exec alpine_2 ping 172.18.0.2
```

![[5.4_result_exec_alpine2.png]]

```bash
docker exec alpine_3 ping 172.17.0.2
```

![[5.4_result_exec_alpine4.png]]

now we'll try to ping a container which is using a different network
```bash
docker exec alpine_3 ping 172.18.0.3
```

![[5.4_result_exec_ping.png]]

As you can see the connection won't be established.
